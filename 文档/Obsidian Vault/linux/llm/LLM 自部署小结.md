# å¼€æºè·¨å¹³å°
## llama.cpp
>LLM inference in C/C++

[ggerganov/llama.cpp: LLM inference in C/C++](https://github.com/ggerganov/llama.cpp)

## ollama
> Get up and running with large language models.
> 
> RunÂ [Llama 3.3](https://ollama.com/library/llama3.3),Â [Phi 4](https://ollama.com/library/phi4),Â [Mistral](https://ollama.com/library/mistral),Â [Gemma 2](https://ollama.com/library/gemma2), and other models. Customize and create your own.

[Ollama](https://ollama.com/)
[ollama/ollama: Get up and running with Llama 3.3, Phi 4, Gemma 2, and other large language models.](https://github.com/ollama/ollama)

## lmstudio.ai
>Discover, download, and run local LLMs

[lmstudio.ai](https://lmstudio.ai/)
[LM Studio](https://github.com/lmstudio-ai)

## Jan
>Jan is an open source alternative to ChatGPT that runs 100% offline on your computer

Linux+MacOS+Windows
[Jan: Open source ChatGPT-alternative that runs 100% offline - Jan](https://jan.ai/)
[janhq/jan: Jan is an open source alternative to ChatGPT that runs 100% offline on your computer](https://github.com/janhq/jan)

## LocalAI
>ğŸ¤– The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference

Mac(Apple Silicion M+Intel)+Linux(arm64+x86_64)

[mudler/LocalAI: :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference](https://github.com/mudler/LocalAI

## MLC LLM
>Universal LLM Deployment Engine with ML Compilation

Python+iOS+Android+Web(å¯¹ï¼Œå°±æ˜¯ç›´æ¥åœ¨webç«¯æ‰§è¡Œ[WebLLM Chat](https://chat.webllm.ai/))
[mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML Compilation](https://github.com/mlc-ai/mlc-llm)
[MLC LLM | Home](https://llm.mlc.ai/)

## pocketpal-ai
>pocketpal-ai

iOS+Android
[a-ghorbani/pocketpal-ai: An app that brings language models directly to your phone.](https://github.com/a-ghorbani/pocketpal-ai)
## VLLM
>A high-throughput and memory-efficient inference and serving engine for LLMs

Python
[Welcome to vLLM â€” vLLM](https://docs.vllm.ai/en/latest/#)
[vllm-project/vllm: A high-throughput and memory-efficient inference and serving engine for LLMs](https://github.com/vllm-project/vllm)
## node-llama-cpp
>Run AI models locally on your machine with node.js bindings for llama.cpp. Enforce a JSON schema on the model output on the generation level

node.js with example(Linux+macOS+Windows)
[node-llama-cpp | Run AI models locally on your machine](https://node-llama-cpp.withcat.ai/)
[withcatai/node-llama-cpp: Run AI models locally on your machine with node.js bindings for llama.cpp. Enforce a JSON schema on the model output on the generation level](https://github.com/withcatai/node-llama-cpp)

## Text Generation Inference
>Text Generation Inference (TGI) is a toolkit for deploying and serving Large Language Models (LLMs). TGI enables high-performance text generation for the most popular open-source LLMs, including Llama, Falcon, StarCoder, BLOOM, GPT-NeoX, and T5.

[Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index)
[huggingface/text-generation-inference: Large Language Model Text Generation Inference](https://github.com/huggingface/text-generation-inference)

## anythingllm
>The all-in-one AI application

MacOS+Windows+Linux
[AnythingLLM | The all-in-one AI application for everyone](https://anythingllm.com/)
[Mintplex-Labs/anything-llm: The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.](https://github.com/Mintplex-Labs/anything-llm)

## Cortex.cpp
>Run and Customize Local LLMs

Windows+Linux+MacOS
[janhq/cortex.cpp: Local AI API Platform](https://github.com/janhq/cortex.cpp)
[Homepage - Cortex](https://cortex.so/)
## catai
>Run AI âœ¨ assistant locally! with simple API for Node.js ğŸš€

node.js
[withcatai/catai: Run AI âœ¨ assistant locally! with simple API for Node.js ğŸš€](https://github.com/withcatai/catai)

## edgen
>âš¡ Edgen: Local, private GenAI server alternative to OpenAI. No GPU required. Run AI models locally: LLMs (Llama2, Mistral, Mixtral...), Speech-to-text (whisper) and many others.

[docs.edgen.co/](https://docs.edgen.co/ "https://docs.edgen.co/")
[edgenai/edgen: âš¡ Edgen: Local, private GenAI server alternative to OpenAI. No GPU required. Run AI models locally: LLMs (Llama2, Mistral, Mixtral...), Speech-to-text (whisper) and many others.](https://github.com/edgenai/edgen)
## ariya
[ariya/ask-llm: Interact with any LLM service](https://github.com/ariya/ask-llm)
[ariya/query-llm: Query LLM with Chain-of-Tought](https://github.com/ariya/query-llm)

# å¼€æºå•ä¸€å¹³å°
## ollama-app
>A modern and easy-to-use client for Ollama

Android
[JHubi1/ollama-app: A modern and easy-to-use client for Ollama](https://github.com/JHubi1/ollama-app)

## LMPlayground
>Language Model Playground

Android
[andriydruk/LMPlayground: Language Model Playground](https://github.com/andriydruk/LMPlayground)

## mLLM
>Fast Multimodal LLM on Mobile Devices

Android
[UbiquitousLearning/mllm: Fast Multimodal LLM on Mobile Devices](https://github.com/UbiquitousLearning/mLLM)
# é—­æºå…è´¹è·¨å¹³å°

## backyard.ai
>Create Immersive  AI-PoweredÂ Characters

Android+iOS+MacOS(Intel+M1/M2/M3)+Windows
[Backyard AI | Home](https://backyard.ai/)

## jellybox
>åˆ›é€ ï¼Œç”Ÿæˆï¼Œåˆ†äº«ï¼
>åœ¨æœ¬åœ°è¿è¡ŒAIæ¨¡å‹ï¼Œå®Œå…¨è„±æœºï¼

MacOS(Apple Silicion M)+Windows
[Jellybox - Create, Generate, Share!](https://jellybox.com/)

## msty
> The easiest way to useÂ local and online AI models
> > notice:æœ‰å¢å€¼æœåŠ¡

MacOS(Intel+M1/M2/M3/M4)+Windows+Linux
[Msty - Using AI Models made Simple and Easy](https://msty.app/)

## Sanctum
> Your Private Sanctum for AI
>Run & interact with full-featured open-source LLMs locally on your device.  
Your data is encrypted, secure, and never leaves your Sanctum.

MacOS(Intel+M1/M2/M3)+Windows
[Sanctum â€” Your Private, Local AI Assistant](https://sanctum.ai/)

# é—­æºå…è´¹â€”â€”å®‰å“
## Private AI
[Private AI - Google Play ä¸Šçš„åº”ç”¨](https://play.google.com/store/apps/details?id=us.valkon.privateai)
# é—­æºæ”¶è´¹
## Recurse Chat
Mac
[RecurseChat](https://recurse.chat/)

| **åˆ†ç±» (Category)**                               | **åç§° (Name)**                   | **å¹³å° (Platform)**                                    | **æè¿° (Description)**                                                                                                                                   | **é“¾æ¥ (Links)**                                                                                                                                                |
| ----------------------------------------------- | ------------------------------- | ---------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **å¼€æºè·¨å¹³å° (Open Source Cross-Platform)**          | llama.cpp                       | C/C++                                                | C/C++ ä¸­çš„ LLM æ¨ç† (LLM inference in C/C++)                                                                                                               | [GitHub](https://github.com/ggerganov/llama.cpp)                                                                                                              |
|                                                 | ollama                          | Linux, macOS, Windows                                | è½»æ¾è¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ (Get up and running with large language models.)ï¼Œæ”¯æŒ Llama 3.3, Phi 4, Mistral, Gemma 2 ç­‰æ¨¡å‹ï¼Œå¯è‡ªå®šä¹‰å’Œåˆ›å»ºæ¨¡å‹ã€‚                                       | [Ollama](https://ollama.com/) / [GitHub](https://github.com/ollama/ollama)                                                                                    |
|                                                 | lmstudio.ai                     | Linux, macOS, Windows                                | å‘ç°ã€ä¸‹è½½å’Œè¿è¡Œæœ¬åœ° LLM (Discover, download, and run local LLMs)                                                                                                | [lmstudio.ai](https://lmstudio.ai/) / [GitHub](https://github.com/lmstudio-ai)                                                                                |
|                                                 | Jan                             | Linux, macOS, Windows                                | å¼€æº ChatGPT æ›¿ä»£å“ï¼Œ100% ç¦»çº¿è¿è¡Œ (Open source ChatGPT-alternative that runs 100% offline)                                                                      | [Jan](https://jan.ai/) / [GitHub](https://github.com/janhq/jan)                                                                                               |
|                                                 | LocalAI                         | Mac (Apple Silicon M+, Intel), Linux (arm64, x86_64) | å…è´¹å¼€æºçš„ OpenAI ç­‰æ›¿ä»£å“ (The free, Open Source alternative to OpenAI, Claude and others.)ï¼Œè‡ªæ‰˜ç®¡å’Œæœ¬åœ°ä¼˜å…ˆï¼Œæ— éœ€ GPUï¼Œæ”¯æŒå¤šç§æ¨¡å‹æ¶æ„ã€‚                                          | [GitHub](https://github.com/mudler/LocalAI)                                                                                                                   |
|                                                 | MLC LLM                         | Python, iOS, Android, Web                            | é€šç”¨ LLM éƒ¨ç½²å¼•æ“ï¼Œä½¿ç”¨ ML ç¼–è¯‘ (Universal LLM Deployment Engine with ML Compilation)ï¼Œå¯ä»¥ç›´æ¥åœ¨ Web ç«¯æ‰§è¡Œï¼è¶…é…·çš„ï¼ğŸ˜                                                        | [MLC LLM](https://llm.mlc.ai/) / [GitHub](https://github.com/mlc-ai/mlc-llm)                                                                                  |
|                                                 | pocketpal-ai                    | iOS, Android                                         | å°†è¯­è¨€æ¨¡å‹ç›´æ¥å¸¦åˆ°æ‰‹æœºä¸Šçš„åº”ç”¨ (An app that brings language models directly to your phone.)                                                                           | [GitHub](https://github.com/a-ghorbani/pocketpal-ai)                                                                                                          |
|                                                 | VLLM                            | Python                                               | é«˜æ€§èƒ½å’Œå†…å­˜é«˜æ•ˆçš„ LLM æ¨ç†å’ŒæœåŠ¡å¼•æ“ (A high-throughput and memory-efficient inference and serving engine for LLMs)                                                   | [vLLM](https://docs.vllm.ai/en/latest/#) / [GitHub](https://github.com/vllm-project/vllm)                                                                     |
|                                                 | node-llama-cpp                  | Node.js, Linux, macOS, Windows                       | ä½¿ç”¨ node.js ç»‘å®šåœ¨æœ¬åœ°è¿è¡Œ AI æ¨¡å‹ (Run AI models locally on your machine with node.js bindings for llama.cpp.)ï¼Œåœ¨ç”Ÿæˆçº§åˆ«å¼ºåˆ¶æ‰§è¡Œ JSON æ¨¡å¼ã€‚                               | [node-llama-cpp](https://node-llama-cpp.withcat.ai/) / [GitHub](https://github.com/withcatai/node-llama-cpp)                                                  |
|                                                 | Text Generation Inference (TGI) | -                                                    | ç”¨äºéƒ¨ç½²å’Œ serving å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) çš„å·¥å…·åŒ… (Text Generation Inference (TGI) is a toolkit for deploying and serving Large Language Models (LLMs).)ï¼Œæ”¯æŒå¤šç§æµè¡Œçš„å¼€æº LLMã€‚ | [Text Generation Inference](https://huggingface.co/docs/text-generation-inference/index) / [GitHub](https://github.com/huggingface/text-generation-inference) |
|                                                 | anythingllm                     | macOS, Windows, Linux                                | ä¸€ä½“åŒ– AI åº”ç”¨ç¨‹åº (The all-in-one AI application)                                                                                                            | [AnythingLLM](https://anythingllm.com/) / [GitHub](https://github.com/Mintplex-Labs/anything-llm)                                                             |
|                                                 | Cortex.cpp                      | Windows, Linux, macOS                                | è¿è¡Œå’Œè‡ªå®šä¹‰æœ¬åœ° LLM (Run and Customize Local LLMs)ï¼Œæœ¬åœ° AI API å¹³å°ã€‚                                                                                              | [Cortex](https://cortex.so/) / [GitHub](https://github.com/janhq/cortex.cpp)                                                                                  |
|                                                 | catai                           | node.js                                              | æœ¬åœ°è¿è¡Œ AI åŠ©æ‰‹ï¼Œæä¾›ç®€å•çš„ Node.js API (Run AI âœ¨ assistant locally! with simple API for Node.js ğŸš€)                                                              | [GitHub](https://github.com/withcatai/catai)                                                                                                                  |
|                                                 | edgen                           | Linux, macOS, Windows                                | æœ¬åœ°ã€ç§æœ‰çš„ GenAI æœåŠ¡å™¨ï¼ŒOpenAI çš„æ›¿ä»£å“ (Local, private GenAI server alternative to OpenAI.)ï¼Œæ— éœ€ GPUï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œè¯­éŸ³è½¬æ–‡æœ¬ã€‚                                                 | [edgen](https://docs.edgen.co/) / [GitHub](https://github.com/edgenai/edgen)                                                                                  |
|                                                 | ask-llm (ariya)                 | -                                                    | ä¸ä»»ä½• LLM æœåŠ¡äº¤äº’ (Interact with any LLM service)                                                                                                           | [GitHub](https://github.com/ariya/ask-llm)                                                                                                                    |
|                                                 | query-llm (ariya)               | -                                                    | ä½¿ç”¨ Chain-of-Thought æŸ¥è¯¢ LLM (Query LLM with Chain-of-Thought)                                                                                           | [GitHub](https://github.com/ariya/query-llm)                                                                                                                  |
| **å¼€æºå•ä¸€å¹³å° (Open Source Single-Platform)**        | ollama-app                      | Android                                              | Ollama çš„ç°ä»£ä¸”æ˜“äºä½¿ç”¨çš„å®¢æˆ·ç«¯ (A modern and easy-to-use client for Ollama)                                                                                       | [GitHub](https://github.com/JHubi1/ollama-app)                                                                                                                |
|                                                 | LMPlayground                    | Android                                              | è¯­è¨€æ¨¡å‹æ¸¸ä¹åœº (Language Model Playground)                                                                                                                    | [GitHub](https://github.com/andriydruk/LMPlayground)                                                                                                          |
|                                                 | mLLM                            | Android                                              | ç§»åŠ¨è®¾å¤‡ä¸Šçš„å¿«é€Ÿå¤šæ¨¡æ€ LLM (Fast Multimodal LLM on Mobile Devices)                                                                                                | [GitHub](https://github.com/UbiquitousLearning/mLLM)                                                                                                          |
| **é—­æºå…è´¹è·¨å¹³å° (Closed Source Free Cross-Platform)** | backyard.ai                     | Android, iOS, macOS (Intel, M1/M2/M3), Windows       | åˆ›å»ºæ²‰æµ¸å¼ AI é©±åŠ¨çš„è§’è‰² (Create Immersive AI-Powered Characters)                                                                                                | [Backyard AI](https://backyard.ai/)                                                                                                                           |
|                                                 | jellybox                        | macOS (Apple Silicon M), Windows                     | åˆ›é€ ï¼Œç”Ÿæˆï¼Œåˆ†äº«ï¼æœ¬åœ°è¿è¡Œ AI æ¨¡å‹ï¼Œå®Œå…¨è„±æœºï¼(Create, Generate, Share! Run AI models locally, completely offline!)                                                         | [Jellybox](https://jellybox.com/)                                                                                                                             |
|                                                 | msty                            | macOS (Intel, M1/M2/M3/M4), Windows, Linux           | ä½¿ç”¨æœ¬åœ°å’Œåœ¨çº¿ AI æ¨¡å‹çš„æœ€ç®€å•æ–¹æ³• (The easiest way to use local and online AI models)ï¼Œæ³¨æ„æœ‰å¢å€¼æœåŠ¡å“¦ï¼                                                                      | [Msty](https://msty.app/)                                                                                                                                     |
|                                                 | Sanctum                         | macOS (Intel, M1/M2/M3), Windows                     | æ‚¨çš„ç§äºº AI åœ£æ‰€ (Your Private Sanctum for AI)ï¼Œåœ¨æœ¬åœ°è®¾å¤‡ä¸Šè¿è¡Œå…¨åŠŸèƒ½å¼€æº LLMï¼Œæ•°æ®åŠ å¯†å®‰å…¨ã€‚                                                                                     | [Sanctum](https://sanctum.ai/)                                                                                                                                |
| **é—­æºå…è´¹ - å®‰å“ (Closed Source Free - Android)**    | Private AI                      | Android                                              | ç§æœ‰ AI åº”ç”¨ (Private AI App)                                                                                                                              | [Google Play](https://play.google.com/store/apps/details?id=us.valkon.privateai)                                                                              |
| **é—­æºæ”¶è´¹ (Closed Source Paid)**                   | Recurse Chat                    | Mac                                                  | Mac å¹³å°çš„èŠå¤©åº”ç”¨ (Mac Chat Application)                                                                                                                     | [RecurseChat](https://recurse.chat/)                                                                                                                          |
